{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBeCdjND3Aa3"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "Lhaecqa-3FW_"
      },
      "outputs": [],
      "source": [
        "# load the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "UPF0PbeE3Fo3"
      },
      "outputs": [],
      "source": [
        "# set seeds\n",
        "SEED = 42\n",
        "def set_seeds(seed):\n",
        "  '''Sets seed for reproduciability'''\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seeds(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # set device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JXTbX2xM2qsS",
        "outputId": "5d57cce0-b736-48f6-f21f-9748e136c0ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          title  category\n",
              "0  BBC set for major shake-up, claims newspaper  Business\n",
              "1                      Marsh averts cash crunch  Business\n",
              "2      Jeter, Yankees Look to Take Control (AP)    Sports\n",
              "3                      Flying the Sun to Safety  Sci/Tech\n",
              "4      Stocks Seen Flat as Nortel and Oil Weigh  Business"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-382351e4-c9dd-4e46-9bb5-2f8111d72ec9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BBC set for major shake-up, claims newspaper</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Marsh averts cash crunch</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jeter, Yankees Look to Take Control (AP)</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Flying the Sun to Safety</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stocks Seen Flat as Nortel and Oil Weigh</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-382351e4-c9dd-4e46-9bb5-2f8111d72ec9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-382351e4-c9dd-4e46-9bb5-2f8111d72ec9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-382351e4-c9dd-4e46-9bb5-2f8111d72ec9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/Made-With-ML/main/datasets/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yyixrQ94NYV"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "EjLu2jj-4Jh0"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHeyDInl4TX8",
        "outputId": "766fa2fe-a1b8-4bbb-f85a-52931bc5cce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = stopwords.words(\"english\")\n",
        "print (STOPWORDS[:5])\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "yJaShXON4WJL"
      },
      "outputs": [],
      "source": [
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
        "    text = pattern.sub(\"\", text)\n",
        "\n",
        "    # Remove words in parenthesis\n",
        "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)  # separate punctuation tied to words\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmx_pJO84c8c",
        "outputId": "fcc2365e-c2cd-44a5-b34c-e1fa775ed920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbc set major shake claims newspaper\n"
          ]
        }
      ],
      "source": [
        "# test preprocessing\n",
        "text  = 'BBC set for major shake-up, claims newspaper'\n",
        "print(preprocess(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j2CuTz9K4udQ",
        "outputId": "d4337df0-241c-4bd3-be9f-c18a0f8528e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  title  category\n",
              "0  bbc set major shake claims newspaper  Business\n",
              "1              marsh averts cash crunch  Business\n",
              "2       jeter yankees look take control    Sports\n",
              "3                     flying sun safety  Sci/Tech\n",
              "4     stocks seen flat nortel oil weigh  Business"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7c39d41-f1fa-49f1-a6fb-5c4c45e2d79e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bbc set major shake claims newspaper</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marsh averts cash crunch</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jeter yankees look take control</td>\n",
              "      <td>Sports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>flying sun safety</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stocks seen flat nortel oil weigh</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7c39d41-f1fa-49f1-a6fb-5c4c45e2d79e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7c39d41-f1fa-49f1-a6fb-5c4c45e2d79e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7c39d41-f1fa-49f1-a6fb-5c4c45e2d79e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "# Now apply preprocessing to the whole dataframe\n",
        "df.title = df.title.apply(preprocess)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APqhp6zk5EGN"
      },
      "source": [
        "### Spliting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "zcDyF3ZS5uFp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "7LolXbEV5BX0"
      },
      "outputs": [],
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15\n",
        "\n",
        "def get_data_splits(X, y, train_size = TRAIN_SIZE):\n",
        "  X_train, X_ , y_train, y_ = train_test_split(X, y, train_size = train_size, shuffle = True, stratify= y)\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X, y, train_size = 0.5, stratify= y)\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YRP2dt36MCy",
        "outputId": "4e298cb0-1afb-4343-a2d6-6872646649de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (60000,), y_val: (60000,)\n",
            "X_test: (60000,), y_test: (60000,)\n",
            "Sample point: ibm pay 320m partially settle pension case → Sci/Tech\n"
          ]
        }
      ],
      "source": [
        "# create datasplits\n",
        "X , y= df.title.values , df.category.values\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = get_data_splits(X, y)\n",
        "print (f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
        "print (f'X_val: {X_val.shape}, y_val: {y_val.shape}')\n",
        "print (f'X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
        "print (f'Sample point: {X_train[0]} → {y_train[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN4HUyp96kGf"
      },
      "source": [
        "### Encoding\n",
        "\n",
        "here we would build a custom encoder class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "rEChpree_m40"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "YPXrIZ4K6i8O"
      },
      "outputs": [],
      "source": [
        "class LabelEncoder(object):\n",
        "  ''' Encodes and decodes class labels as required'''\n",
        "\n",
        "  def __init__(self, class_to_index = None):\n",
        "      self.class_to_index = {} if class_to_index is None else class_to_index\n",
        "      self.index_to_class = {v:k for k,v in self.class_to_index.items()}\n",
        "      self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "  def fit(self, y):\n",
        "      classes = np.unique(y)\n",
        "      for i, value in enumerate(classes):\n",
        "        self.class_to_index[value] = i\n",
        "      self.index_to_class = {v:k for k,v in self.class_to_index.items()}\n",
        "      self.classes = list(self.class_to_index.keys())\n",
        "      return self\n",
        "\n",
        "  def encode(self, y):\n",
        "      labels = np.vectorize(self.class_to_index.get)(y)\n",
        "      return np.asarray(labels)\n",
        "\n",
        "  def decode(self, y):\n",
        "    labels = np.vectorize(self.index_to_class.get)(y)\n",
        "    return labels\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "      return f'<LabelEncoder(), number of classes - {len(self)}'\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.class_to_index)\n",
        "\n",
        "  def save(self, fp):\n",
        "      with open(fp, 'w') as fp:\n",
        "        contents = {'class_to_index': self.class_to_index}\n",
        "        json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "  \n",
        "  @classmethod\n",
        "  def load(cls, fp):\n",
        "      with open(fp, 'r') as fp:\n",
        "        kwargs = json.load(fp=fp)\n",
        "      return cls(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhNFIMWy6ely",
        "outputId": "22f0f6b8-aad7-45de-9688-0b00dd0a2332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['amsterdam', 'paris', 'tokyo']\n",
            "[1 1 2 0]\n",
            "['paris' 'paris' 'tokyo' 'amsterdam']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# test Encoder\n",
        "y = ['paris', 'paris', 'tokyo', 'amsterdam']\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "print(encoder.classes)\n",
        "print(encoder.encode(y))\n",
        "print(encoder.decode(encoder.encode(y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaCI8Z6mDaUV",
        "outputId": "22c9c25d-d10f-44bd-e960-1723ac6f769f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "NUM_CLASSES = len(label_encoder)\n",
        "label_encoder.class_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NaM_fPpCgXS",
        "outputId": "3f8c6a0f-5568-40e8-90b9-3bddef855a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train[0]: Sci/Tech\n",
            "y_train[0]: 1\n"
          ]
        }
      ],
      "source": [
        "# Convert labels to tokens\n",
        "print (f'y_train[0]: {y_train[0]}')\n",
        "y_train = label_encoder.encode(y_train)\n",
        "y_val = label_encoder.encode(y_val)\n",
        "y_test = label_encoder.encode(y_test)\n",
        "print (f'y_train[0]: {y_train[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbSXGjZ3LYP7"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "We would also build our custom tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "Hq7C-n8ETnLz"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from more_itertools import take"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "BD8cx2CaF2p9"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "\n",
        "  \"\"\"Tokenize texts to indexes using ) as Padindex and 1 as UNK index\"\"\"\n",
        "\n",
        "  def __init__(self, type : str = 'word', num_tokens = None, \n",
        "               pad_token='<PAD>', oov_token='<UNK>',token_to_index = None) -> None:\n",
        "      self.type = type\n",
        "      if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "      self.num_tokens = num_tokens\n",
        "      self.pad_token = pad_token\n",
        "      self.oov_token = oov_token\n",
        "      if token_to_index is None:\n",
        "        token_to_index = {pad_token: 0, oov_token: 1}\n",
        "      self.token_to_index = token_to_index\n",
        "      self.index_to_token = {v:k for k, v in self.token_to_index.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.token_to_index)\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "      return f'<Tokenizer(num_tokens={len(self)})>'\n",
        "\n",
        "  def fit_on_texts(self, texts):\n",
        "      all_texts = []\n",
        "      for text in texts:\n",
        "        tokens = [*text] if self.type == 'char' else text.split()\n",
        "        all_texts.extend(tokens)\n",
        "      counts = Counter(all_texts).most_common(self.num_tokens)\n",
        "      self.min_token_freq = counts[-1][1]\n",
        "      for word, _ in counts:\n",
        "        self.token_to_index[word] = len(self.token_to_index)\n",
        "      self.index_to_token = {v:k for k, v in self.token_to_index.items()}\n",
        "      return self\n",
        "\n",
        "  def texts_to_sequences(self, texts):\n",
        "      sequences = []\n",
        "      for text in texts:\n",
        "        tokens = [*text] if self.type == 'char' else text.split()\n",
        "        indices = []\n",
        "        for token in tokens:\n",
        "          indices.append(self.token_to_index.get(token, self.token_to_index[self.oov_token]))\n",
        "        sequences.append(np.asarray(indices))\n",
        "      return sequences\n",
        "\n",
        "  def sequences_to_texts(self, sequence):\n",
        "      texts = []\n",
        "      for seq in sequence:\n",
        "        tokens = []\n",
        "        for i in seq:\n",
        "          tokens.append(self.index_to_token.get(i, self.num_tokens))\n",
        "        texts.append(tokens)\n",
        "      return texts\n",
        "\n",
        "  def save(self, fp):\n",
        "      with open(fp, 'w') as fp:\n",
        "        contents = {'type': self.type, 'oov_token': self.oov_token,\n",
        "                    'token_to_index': self.token_to_index}\n",
        "        json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "  \n",
        "  @classmethod\n",
        "  def load(cls, fp):\n",
        "      with open(fp, 'r') as fp:\n",
        "        kwargs = json.load(fp=fp)\n",
        "      return cls(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucKrSALDcVep",
        "outputId": "d16fe5a8-7486-41b6-8dff-156e06d0fc83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ibm pay 320m partially settle pension case\n",
            "[2 3 4 1 1 1 1]\n",
            "['ibm', 'pay', '320m', '<UNK>', '<UNK>', '<UNK>', '<UNK>']\n"
          ]
        }
      ],
      "source": [
        "# test tokenizer\n",
        "texts = X_train[0:3]\n",
        "print(texts[0])\n",
        "tokenizer = Tokenizer(type = 'word',num_tokens= 5)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequence = tokenizer.texts_to_sequences(texts)\n",
        "print(sequence[0])\n",
        "new_texts = tokenizer.sequences_to_texts(sequence)\n",
        "print(new_texts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL0lhxyJOqH-",
        "outputId": "45ac408c-a3c6-4394-a9cd-a6a6327cd69f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Tokenizer(num_tokens=500)>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(num_tokens=500)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7bCJ0jlOrnh",
        "outputId": "ae478261-4f3e-4647-a2c6-20e8a407628c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 165\n"
          ]
        }
      ],
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzEmhp0NRIdV",
        "outputId": "5d7a4f20-7581-48c3-8d32-b19dc04b5649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → ['ibm', 'pay', '<UNK>', '<UNK>', '<UNK>', '<UNK>', 'case']\n",
            "  (tokenized) → [ 30 187   1   1   1   1 103]\n"
          ]
        }
      ],
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print ('Text to indices:\\n'\n",
        "    f'  (preprocessed) → {preprocessed_text}\\n'\n",
        "    f'  (tokenized) → {X_train[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "rp0rUH304uqA"
      },
      "outputs": [],
      "source": [
        "# pad sequences to ensure consistency in shape\n",
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "  size = len(sequences)\n",
        "  max_seq_len= max(max_seq_len , max(len(sequence) for sequence in sequences))\n",
        "  padded_sequences = np.zeros((size, max_seq_len), dtype= int)\n",
        "  for i, row in enumerate(sequences):\n",
        "    padded_sequences[i,:len(row)] = row\n",
        "\n",
        "  return padded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT2tmdoC-Anp",
        "outputId": "178de2db-ba32-471b-c21a-371065f49a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 7)\n",
            "Unpadded at index 0 -> [  1 347   2   7   1]\n",
            "padded at index 0 -> [  1 347   2   7   1   0   0]\n"
          ]
        }
      ],
      "source": [
        "# test padding\n",
        "padded_train= pad_sequences(X_train[0:3])\n",
        "print(padded_train.shape)\n",
        "print(f'Unpadded at index 0 -> {X_train[1]}')\n",
        "print(f'padded at index 0 -> {padded_train[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yOmKNhd-2Ff"
      },
      "source": [
        "### Build Dataset With Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "4q7PyGos-ywI"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  '''Build a pytorch Dataset that batchs and load data for our model'''\n",
        "\n",
        "  def __init__(self, X, y) -> None:\n",
        "      super().__init__()\n",
        "      self.X = X\n",
        "      self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.y)\n",
        "\n",
        "  def __str__(self):\n",
        "      return f'<Dataset(N={len(self)})>'\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      X = self.X[index]\n",
        "      y = self.y[index]\n",
        "      return [X, len(X), y]\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "      batch = np.array(batch)\n",
        "      X = batch[:, 0]\n",
        "      seq_lens = batch[:, 1]\n",
        "      y = batch[:, 2]\n",
        "      X = pad_sequences(X)\n",
        "\n",
        "      # Cast\n",
        "      X = torch.LongTensor(X.astype(np.int32))\n",
        "      seq_lens = torch.LongTensor(seq_lens.astype(np.int32))\n",
        "      y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "      return X, seq_lens, y\n",
        "\n",
        "  def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "      return torch.utils.data.DataLoader(dataset = self, batch_size= batch_size, \n",
        "                                         collate_fn=self.collate_fn,shuffle=shuffle, drop_last=drop_last,\n",
        "                                         pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Oi_fJ1NBkj_",
        "outputId": "113b05f7-5584-4724-abf1-8cbe9b9dde23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=60000)>\n",
            "  Test dataset: <Dataset(N=60000)>\n",
            "Sample point:\n",
            "  X: [1 1]\n",
            "  y: 2\n"
          ]
        }
      ],
      "source": [
        "# Create datasets for embedding\n",
        "train_dataset = Dataset(X=X_train, y=y_train)\n",
        "val_dataset = Dataset(X=X_val, y=y_val)\n",
        "test_dataset = Dataset(X=X_test, y=y_test)\n",
        "print (\"Datasets:\\n\"\n",
        "    f'  Train dataset:{train_dataset.__str__()}\\n'\n",
        "    f'  Val dataset: {val_dataset.__str__()}\\n'\n",
        "    f'  Test dataset: {test_dataset.__str__()}\\n'\n",
        "    'Sample point:\\n'\n",
        "    f'  X: {test_dataset[0][0]}\\n'\n",
        "    f'  y: {test_dataset[0][1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl3lGbZtBwBB",
        "outputId": "f4258ce7-6635-440a-985a-573d0e8d9ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch:\n",
            "  X: [64, 9]\n",
            "  seq_lens: [64]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([ 30, 187,   1,   1,   1,   1, 103,   0,   0])\n",
            " seq_len: 7\n",
            "  y: 1\n"
          ]
        }
      ],
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(\n",
        "    batch_size=batch_size)\n",
        "batch_X, batch_seq_lens, batch_y = next(iter(train_dataloader))\n",
        "print ('Sample batch:\\n'\n",
        "    f'  X: {list(batch_X.size())}\\n'\n",
        "    f'  seq_lens: {list(batch_seq_lens.size())}\\n'\n",
        "    f'  y: {list(batch_y.size())}\\n'\n",
        "    'Sample point:\\n'\n",
        "    f'  X: {batch_X[0]}\\n'\n",
        "    f' seq_len: {batch_seq_lens[0]}\\n'\n",
        "    f'  y: {batch_y[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFYrr4ERCwEV",
        "outputId": "b3fd179f-007e-4fa8-e078-888a14b590d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 13, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "# test embedding\n",
        "embed = nn.Embedding(num_embeddings=5000, embedding_dim= 100,\n",
        "                     padding_idx= 0)\n",
        "batch_X,seq_len, batch_y = next(iter(test_dataloader))\n",
        "embed(batch_X).shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gather_last_relevant_hidden(hiddens, seq_lens):\n",
        "    \"\"\"Extract and collect the last relevant\n",
        "    hidden state based on the sequence length.\"\"\"\n",
        "    seq_lens = seq_lens.long().detach().cpu().numpy() - 1\n",
        "    out = []\n",
        "    for batch_index, column_index in enumerate(seq_lens):\n",
        "        out.append(hiddens[batch_index, column_index])\n",
        "    return torch.stack(out)"
      ],
      "metadata": {
        "id": "p9X_IvpBU-R1"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 100\n",
        "RNN_HIDDEN_DIM = 128\n",
        "DROPOUT_P = 0.1\n",
        "sequence_size = 8"
      ],
      "metadata": {
        "id": "SUY11bJ9a_U2"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((BATCH_SIZE, sequence_size, EMBEDDING_DIM))\n",
        "rnn = nn.RNN(EMBEDDING_DIM, RNN_HIDDEN_DIM, batch_first=True)\n",
        "seq_lens = torch.randint(high=sequence_size, size=(BATCH_SIZE, ))\n",
        "out, h_n = rnn(x) # h_n is the last hidden state\n",
        "print (\"out: \", out.shape)\n",
        "print (\"h_n: \", h_n.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ9ae24sa3Kf",
        "outputId": "fc97d1ec-6d14-4f19-b308-cb6a2116b268"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out:  torch.Size([64, 8, 128])\n",
            "h_n:  torch.Size([1, 64, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens).squeeze(0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVQsVkzcbLt_",
        "outputId": "004a992a-8f4c-41d6-8c2d-3999cef0f8a7"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(size = (5, 7, 30))\n",
        "b = torch.randint(low = 2, high = 6, size = (5,))\n",
        "print(b)\n",
        "gather_last_relevant_hidden(hiddens=a, seq_lens=b).squeeze(0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoKvL6MzXnZx",
        "outputId": "5816c906-8b0e-4fb3-8ec8-c77c427ed585"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 5, 5, 5, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "5VhPFq80Ew7h"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "  '''RNN model for sequence classification'''\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size,\n",
        "               num_classes, dropout_prob\n",
        "               ) -> None:\n",
        "      super(RNN, self).__init__()\n",
        "      self.num_classes = num_classes\n",
        "      self.embedding = nn.Embedding(num_embeddings= vocab_size, embedding_dim= embedding_dim,\n",
        "                                    padding_idx= 0)\n",
        "      self.rnn = nn.RNN(input_size = embedding_dim, hidden_size= hidden_size,\n",
        "                        num_layers = 2, batch_first = True)\n",
        "      self.dropout = nn.Dropout(dropout_prob)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.fc1 = nn.Linear(in_features= hidden_size, out_features = hidden_size*2)\n",
        "      self.fc2 = nn.Linear(in_features= hidden_size*2, out_features = num_classes)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "      x_in, seq_lens = inputs\n",
        "      x = self.embedding(x_in)\n",
        "      out, h_n = self.rnn(x)\n",
        "      z = gather_last_relevant_hidden(hiddens=out, seq_lens=seq_lens)\n",
        "      z = self.dropout(z)\n",
        "      z = self.relu(self.fc1(z))\n",
        "      z = self.dropout(z)\n",
        "      z = self.fc2(z)\n",
        "      return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "6gvjdf43FRgH"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 100\n",
        "VOCAB_SIZE = 5000\n",
        "HIDDEN_DIM = 128\n",
        "NUM_CLASSES = 4\n",
        "DROPOUT_P = 0.1\n",
        "\n",
        "model = RNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,hidden_size=HIDDEN_DIM,\n",
        "    dropout_prob=DROPOUT_P, num_classes=NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "2ueFu9ByecX8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "y2uHCEQcOL7n"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "  ''' Custom Trainer'''\n",
        "  def __init__(self, model, device,loss_fn=None, optimizer=None, scheduler=None, compute_metrics = None, \n",
        "               train_dataloader = None,val_dataloader =None, num_epochs = None, patience = None) -> None:\n",
        "      self.train_dataloader = train_dataloader\n",
        "      self.val_dataloader = val_dataloader\n",
        "      self.model = model.to(device)\n",
        "      self.num_epochs = num_epochs\n",
        "      self.loss_fn = loss_fn\n",
        "      self.patience = patience\n",
        "      self.patient = patience\n",
        "      self.optimizer = optimizer\n",
        "      self.scheduler = scheduler\n",
        "      self.compute_metrics = compute_metrics\n",
        "      self.device = device\n",
        "\n",
        "  def train_step(self):\n",
        "      '''Perform single training step accross all batches'''\n",
        "      self.model.train()\n",
        "      running_loss = []\n",
        "      y_probs = []\n",
        "      y_trues = []\n",
        "      for i, batch in enumerate(self.train_dataloader):\n",
        "        batch = [item.to(self.device) for item in batch]\n",
        "        inputs, labels = batch[:-1], batch[-1]\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(inputs)\n",
        "        loss = self.loss_fn(outputs,labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        running_loss.append(loss.item())\n",
        "        y_prob = F.softmax(outputs.detach(), dim = -1).cpu().numpy()\n",
        "        y_probs.extend(y_prob)\n",
        "        y_trues.extend(labels.cpu().numpy())\n",
        "\n",
        "      loss = np.asarray(running_loss).mean()\n",
        "      return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "  def eval_step(self, dataloader = None):\n",
        "      '''Perform single evaluation step accross all batches'''\n",
        "      dataloader = self.val_dataloader if dataloader is None else dataloader \n",
        "      self.model.eval()\n",
        "      running_loss = []\n",
        "      y_probs = []\n",
        "      y_trues = []\n",
        "      with torch.inference_mode():\n",
        "        for i, batch in enumerate(self.val_dataloader):\n",
        "          batch = [item.to(self.device) for item in batch]\n",
        "          inputs, labels = batch[:-1], batch[-1]\n",
        "          outputs = self.model(inputs)\n",
        "          loss = self.loss_fn(outputs,labels)\n",
        "          running_loss.append(loss.item())\n",
        "          y_prob = F.softmax(outputs.detach(), dim = -1).cpu().numpy()\n",
        "          y_probs.extend(y_prob)\n",
        "          y_trues.extend(labels.cpu().numpy())\n",
        "\n",
        "      loss = np.asarray(running_loss).mean()\n",
        "      return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "\n",
        "  def predict(self, dataloader):\n",
        "      self.model.eval()\n",
        "      y_probs = []\n",
        "      model = self.model.to('cpu')\n",
        "      with torch.inference_mode():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "          inputs, labels = batch[:-1], batch[-1]\n",
        "          outputs = model(inputs)\n",
        "          probs = F.softmax(outputs, dim = -1)\n",
        "          y_probs.extend(probs)\n",
        "      return np.vstack(y_probs)\n",
        "\n",
        "  def train(self):\n",
        "      best_score = np.inf\n",
        "      best_model = self.model\n",
        "      for epoch in range(self.num_epochs):\n",
        "        if self.patience == 0 :\n",
        "           print('Early Stopping Reached')\n",
        "           break\n",
        "        train_loss, train_y_trues, train_y_probs = self.train_step()\n",
        "        train_score = self.compute_metrics(train_y_trues, train_y_probs)\n",
        "        val_loss, val_y_trues, val_y_probs = self.eval_step()\n",
        "        val_score = self.compute_metrics(train_y_trues, train_y_probs)\n",
        "        self.scheduler.step(val_loss)\n",
        "        if val_loss < best_score:\n",
        "          best_score = val_loss\n",
        "          best_model = self.model\n",
        "          self.patience = self.patient\n",
        "        else:\n",
        "          self.patience -= 1\n",
        "\n",
        "        print(\n",
        "                f'Epoch: {epoch+1} | '\n",
        "                f'train_loss: {train_loss:.5f}, '\n",
        "                f'val_loss: {val_loss:.5f}, '\n",
        "                f'train_{list(train_score.keys())[0]}: {list(train_score.values())[0]:.5f}, '\n",
        "                f'val_{list(val_score.keys())[0]}: {list(val_score.values())[0]:.5f}, '\n",
        "            )\n",
        "\n",
        "      return best_model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "zrmSfQFQOgHB"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_trues, y_probs):\n",
        "  y_preds = np.argmax(y_probs, axis = -1)\n",
        "  score = f1_score(y_trues,y_preds, average = 'macro')\n",
        "  return {'F1_score': score}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "PATIENCE = 10\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)\n",
        "citerion = nn.CrossEntropyLoss(reduction='mean')"
      ],
      "metadata": {
        "id": "TNZo_vJxgdgz"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "TZnmAW7oP7HK"
      },
      "outputs": [],
      "source": [
        "# initialize trainer with arguments\n",
        "trainer = Trainer(train_dataloader= train_dataloader, model = model,\n",
        "                optimizer= optimizer,scheduler = scheduler, compute_metrics = compute_metrics,device = device,\n",
        "                val_dataloader = val_dataloader, loss_fn = citerion,num_epochs = NUM_EPOCHS, patience = PATIENCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03-16NkWRQXo",
        "outputId": "12d929e0-b18c-4890-a909-0dd3db1af149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 1.19800, val_loss: 1.02977, train_F1_score: 0.46144, val_F1_score: 0.46144, \n",
            "Epoch: 2 | train_loss: 0.98806, val_loss: 0.92975, train_F1_score: 0.59402, val_F1_score: 0.59402, \n",
            "Epoch: 3 | train_loss: 0.91517, val_loss: 0.87903, train_F1_score: 0.62883, val_F1_score: 0.62883, \n",
            "Epoch: 4 | train_loss: 0.87289, val_loss: 0.84346, train_F1_score: 0.64960, val_F1_score: 0.64960, \n",
            "Epoch: 5 | train_loss: 0.84457, val_loss: 0.82232, train_F1_score: 0.66188, val_F1_score: 0.66188, \n",
            "Epoch: 6 | train_loss: 0.82388, val_loss: 0.80434, train_F1_score: 0.67057, val_F1_score: 0.67057, \n",
            "Epoch: 7 | train_loss: 0.81048, val_loss: 0.79312, train_F1_score: 0.67669, val_F1_score: 0.67669, \n",
            "Epoch: 8 | train_loss: 0.79976, val_loss: 0.78435, train_F1_score: 0.68031, val_F1_score: 0.68031, \n",
            "Epoch: 9 | train_loss: 0.79009, val_loss: 0.77773, train_F1_score: 0.68413, val_F1_score: 0.68413, \n",
            "Epoch: 10 | train_loss: 0.78210, val_loss: 0.77181, train_F1_score: 0.68774, val_F1_score: 0.68774, \n",
            "Epoch: 11 | train_loss: 0.77658, val_loss: 0.76939, train_F1_score: 0.68926, val_F1_score: 0.68926, \n",
            "Epoch: 12 | train_loss: 0.77117, val_loss: 0.76474, train_F1_score: 0.69163, val_F1_score: 0.69163, \n",
            "Epoch: 13 | train_loss: 0.76536, val_loss: 0.76161, train_F1_score: 0.69308, val_F1_score: 0.69308, \n",
            "Epoch: 14 | train_loss: 0.76116, val_loss: 0.76232, train_F1_score: 0.69564, val_F1_score: 0.69564, \n",
            "Epoch: 15 | train_loss: 0.75682, val_loss: 0.75776, train_F1_score: 0.69638, val_F1_score: 0.69638, \n",
            "Epoch: 16 | train_loss: 0.75341, val_loss: 0.75723, train_F1_score: 0.69851, val_F1_score: 0.69851, \n",
            "Epoch: 17 | train_loss: 0.74995, val_loss: 0.74886, train_F1_score: 0.69914, val_F1_score: 0.69914, \n",
            "Epoch: 18 | train_loss: 0.74629, val_loss: 0.75191, train_F1_score: 0.70030, val_F1_score: 0.70030, \n",
            "Epoch: 19 | train_loss: 0.74338, val_loss: 0.74321, train_F1_score: 0.70125, val_F1_score: 0.70125, \n",
            "Epoch: 20 | train_loss: 0.73930, val_loss: 0.74694, train_F1_score: 0.70308, val_F1_score: 0.70308, \n",
            "Epoch: 21 | train_loss: 0.73670, val_loss: 0.74575, train_F1_score: 0.70354, val_F1_score: 0.70354, \n",
            "Epoch: 22 | train_loss: 0.73396, val_loss: 0.74135, train_F1_score: 0.70626, val_F1_score: 0.70626, \n",
            "Epoch: 23 | train_loss: 0.73091, val_loss: 0.73972, train_F1_score: 0.70596, val_F1_score: 0.70596, \n",
            "Epoch: 24 | train_loss: 0.72755, val_loss: 0.73803, train_F1_score: 0.70706, val_F1_score: 0.70706, \n",
            "Epoch: 25 | train_loss: 0.72410, val_loss: 0.73939, train_F1_score: 0.70861, val_F1_score: 0.70861, \n",
            "Epoch: 26 | train_loss: 0.72205, val_loss: 0.73519, train_F1_score: 0.70973, val_F1_score: 0.70973, \n",
            "Epoch: 27 | train_loss: 0.71922, val_loss: 0.74037, train_F1_score: 0.71119, val_F1_score: 0.71119, \n",
            "Epoch: 28 | train_loss: 0.71723, val_loss: 0.73878, train_F1_score: 0.71211, val_F1_score: 0.71211, \n",
            "Epoch: 29 | train_loss: 0.71348, val_loss: 0.73121, train_F1_score: 0.71313, val_F1_score: 0.71313, \n",
            "Epoch: 30 | train_loss: 0.71083, val_loss: 0.73028, train_F1_score: 0.71396, val_F1_score: 0.71396, \n",
            "Epoch: 31 | train_loss: 0.70838, val_loss: 0.72298, train_F1_score: 0.71505, val_F1_score: 0.71505, \n",
            "Epoch: 32 | train_loss: 0.70511, val_loss: 0.72170, train_F1_score: 0.71644, val_F1_score: 0.71644, \n",
            "Epoch: 33 | train_loss: 0.70234, val_loss: 0.72473, train_F1_score: 0.71742, val_F1_score: 0.71742, \n",
            "Epoch: 34 | train_loss: 0.70010, val_loss: 0.72179, train_F1_score: 0.71877, val_F1_score: 0.71877, \n",
            "Epoch: 35 | train_loss: 0.69732, val_loss: 0.72027, train_F1_score: 0.71840, val_F1_score: 0.71840, \n",
            "Epoch: 36 | train_loss: 0.69425, val_loss: 0.71986, train_F1_score: 0.72032, val_F1_score: 0.72032, \n",
            "Epoch: 37 | train_loss: 0.69096, val_loss: 0.71836, train_F1_score: 0.72179, val_F1_score: 0.72179, \n",
            "Epoch: 38 | train_loss: 0.68846, val_loss: 0.71861, train_F1_score: 0.72235, val_F1_score: 0.72235, \n",
            "Epoch: 39 | train_loss: 0.68544, val_loss: 0.71599, train_F1_score: 0.72349, val_F1_score: 0.72349, \n",
            "Epoch: 40 | train_loss: 0.68221, val_loss: 0.70745, train_F1_score: 0.72620, val_F1_score: 0.72620, \n",
            "Epoch: 41 | train_loss: 0.67938, val_loss: 0.70751, train_F1_score: 0.72671, val_F1_score: 0.72671, \n",
            "Epoch: 42 | train_loss: 0.67686, val_loss: 0.71558, train_F1_score: 0.72697, val_F1_score: 0.72697, \n",
            "Epoch: 43 | train_loss: 0.67261, val_loss: 0.70238, train_F1_score: 0.72890, val_F1_score: 0.72890, \n",
            "Epoch: 44 | train_loss: 0.67029, val_loss: 0.69745, train_F1_score: 0.72986, val_F1_score: 0.72986, \n",
            "Epoch: 45 | train_loss: 0.66683, val_loss: 0.70677, train_F1_score: 0.73106, val_F1_score: 0.73106, \n",
            "Epoch: 46 | train_loss: 0.66376, val_loss: 0.69649, train_F1_score: 0.73243, val_F1_score: 0.73243, \n",
            "Epoch: 47 | train_loss: 0.66015, val_loss: 0.69926, train_F1_score: 0.73306, val_F1_score: 0.73306, \n",
            "Epoch: 48 | train_loss: 0.65723, val_loss: 0.69191, train_F1_score: 0.73492, val_F1_score: 0.73492, \n",
            "Epoch: 49 | train_loss: 0.65409, val_loss: 0.69104, train_F1_score: 0.73608, val_F1_score: 0.73608, \n",
            "Epoch: 50 | train_loss: 0.65168, val_loss: 0.68586, train_F1_score: 0.73618, val_F1_score: 0.73618, \n"
          ]
        }
      ],
      "source": [
        "# train and return best model\n",
        "best_model = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyrzGrx7dvYL",
        "outputId": "4c2bccca-1837-486a-cd34-e66512866b37"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.64819, val_loss: 0.69017, train_F1_score: 0.73837, val_F1_score: 0.73837, \n",
            "Epoch: 2 | train_loss: 0.64512, val_loss: 0.68256, train_F1_score: 0.73941, val_F1_score: 0.73941, \n",
            "Epoch: 3 | train_loss: 0.64147, val_loss: 0.68510, train_F1_score: 0.74057, val_F1_score: 0.74057, \n",
            "Epoch: 4 | train_loss: 0.63679, val_loss: 0.68137, train_F1_score: 0.74348, val_F1_score: 0.74348, \n",
            "Epoch: 5 | train_loss: 0.63456, val_loss: 0.67768, train_F1_score: 0.74371, val_F1_score: 0.74371, \n",
            "Epoch: 6 | train_loss: 0.63027, val_loss: 0.68268, train_F1_score: 0.74558, val_F1_score: 0.74558, \n",
            "Epoch: 7 | train_loss: 0.62733, val_loss: 0.68096, train_F1_score: 0.74570, val_F1_score: 0.74570, \n",
            "Epoch: 8 | train_loss: 0.62326, val_loss: 0.67187, train_F1_score: 0.74765, val_F1_score: 0.74765, \n",
            "Epoch: 9 | train_loss: 0.62054, val_loss: 0.67408, train_F1_score: 0.74869, val_F1_score: 0.74869, \n",
            "Epoch: 10 | train_loss: 0.61740, val_loss: 0.66718, train_F1_score: 0.74976, val_F1_score: 0.74976, \n",
            "Epoch: 11 | train_loss: 0.61379, val_loss: 0.66925, train_F1_score: 0.75183, val_F1_score: 0.75183, \n",
            "Epoch: 12 | train_loss: 0.61119, val_loss: 0.67502, train_F1_score: 0.75198, val_F1_score: 0.75198, \n",
            "Epoch: 13 | train_loss: 0.60782, val_loss: 0.67275, train_F1_score: 0.75430, val_F1_score: 0.75430, \n",
            "Epoch: 14 | train_loss: 0.60406, val_loss: 0.66838, train_F1_score: 0.75490, val_F1_score: 0.75490, \n",
            "Epoch: 15 | train_loss: 0.58947, val_loss: 0.64831, train_F1_score: 0.76061, val_F1_score: 0.76061, \n",
            "Epoch: 16 | train_loss: 0.58601, val_loss: 0.64720, train_F1_score: 0.76219, val_F1_score: 0.76219, \n",
            "Epoch: 17 | train_loss: 0.58545, val_loss: 0.64579, train_F1_score: 0.76206, val_F1_score: 0.76206, \n",
            "Epoch: 18 | train_loss: 0.58252, val_loss: 0.64542, train_F1_score: 0.76477, val_F1_score: 0.76477, \n",
            "Epoch: 19 | train_loss: 0.58251, val_loss: 0.64488, train_F1_score: 0.76404, val_F1_score: 0.76404, \n",
            "Epoch: 20 | train_loss: 0.58159, val_loss: 0.64376, train_F1_score: 0.76396, val_F1_score: 0.76396, \n",
            "Epoch: 21 | train_loss: 0.58168, val_loss: 0.64365, train_F1_score: 0.76419, val_F1_score: 0.76419, \n",
            "Epoch: 22 | train_loss: 0.58044, val_loss: 0.64418, train_F1_score: 0.76494, val_F1_score: 0.76494, \n",
            "Epoch: 23 | train_loss: 0.57990, val_loss: 0.64336, train_F1_score: 0.76526, val_F1_score: 0.76526, \n",
            "Epoch: 24 | train_loss: 0.57941, val_loss: 0.64362, train_F1_score: 0.76497, val_F1_score: 0.76497, \n",
            "Epoch: 25 | train_loss: 0.57730, val_loss: 0.64323, train_F1_score: 0.76609, val_F1_score: 0.76609, \n",
            "Epoch: 26 | train_loss: 0.57757, val_loss: 0.64319, train_F1_score: 0.76632, val_F1_score: 0.76632, \n",
            "Epoch: 27 | train_loss: 0.57765, val_loss: 0.64263, train_F1_score: 0.76560, val_F1_score: 0.76560, \n",
            "Epoch: 28 | train_loss: 0.57593, val_loss: 0.64238, train_F1_score: 0.76613, val_F1_score: 0.76613, \n",
            "Epoch: 29 | train_loss: 0.57621, val_loss: 0.64249, train_F1_score: 0.76542, val_F1_score: 0.76542, \n",
            "Epoch: 30 | train_loss: 0.57530, val_loss: 0.64215, train_F1_score: 0.76604, val_F1_score: 0.76604, \n",
            "Epoch: 31 | train_loss: 0.57599, val_loss: 0.64205, train_F1_score: 0.76671, val_F1_score: 0.76671, \n",
            "Epoch: 32 | train_loss: 0.57494, val_loss: 0.64173, train_F1_score: 0.76624, val_F1_score: 0.76624, \n",
            "Epoch: 33 | train_loss: 0.57284, val_loss: 0.64144, train_F1_score: 0.76783, val_F1_score: 0.76783, \n",
            "Epoch: 34 | train_loss: 0.57375, val_loss: 0.64156, train_F1_score: 0.76723, val_F1_score: 0.76723, \n",
            "Epoch: 35 | train_loss: 0.57255, val_loss: 0.64131, train_F1_score: 0.76819, val_F1_score: 0.76819, \n",
            "Epoch: 36 | train_loss: 0.57235, val_loss: 0.64115, train_F1_score: 0.76790, val_F1_score: 0.76790, \n",
            "Epoch: 37 | train_loss: 0.57177, val_loss: 0.64093, train_F1_score: 0.76784, val_F1_score: 0.76784, \n",
            "Epoch: 38 | train_loss: 0.57075, val_loss: 0.63971, train_F1_score: 0.76858, val_F1_score: 0.76858, \n",
            "Epoch: 39 | train_loss: 0.56996, val_loss: 0.64198, train_F1_score: 0.76904, val_F1_score: 0.76904, \n",
            "Epoch: 40 | train_loss: 0.56957, val_loss: 0.63990, train_F1_score: 0.76897, val_F1_score: 0.76897, \n",
            "Epoch: 41 | train_loss: 0.56956, val_loss: 0.63977, train_F1_score: 0.76961, val_F1_score: 0.76961, \n",
            "Epoch: 42 | train_loss: 0.56863, val_loss: 0.64018, train_F1_score: 0.76934, val_F1_score: 0.76934, \n",
            "Epoch: 43 | train_loss: 0.56732, val_loss: 0.63693, train_F1_score: 0.76966, val_F1_score: 0.76966, \n",
            "Epoch: 44 | train_loss: 0.56538, val_loss: 0.63667, train_F1_score: 0.77042, val_F1_score: 0.77042, \n",
            "Epoch: 45 | train_loss: 0.56655, val_loss: 0.63662, train_F1_score: 0.77042, val_F1_score: 0.77042, \n",
            "Epoch: 46 | train_loss: 0.56531, val_loss: 0.63650, train_F1_score: 0.77005, val_F1_score: 0.77005, \n",
            "Epoch: 47 | train_loss: 0.56562, val_loss: 0.63660, train_F1_score: 0.77127, val_F1_score: 0.77127, \n",
            "Epoch: 48 | train_loss: 0.56489, val_loss: 0.63649, train_F1_score: 0.77165, val_F1_score: 0.77165, \n",
            "Epoch: 49 | train_loss: 0.56629, val_loss: 0.63652, train_F1_score: 0.77065, val_F1_score: 0.77065, \n",
            "Epoch: 50 | train_loss: 0.56641, val_loss: 0.63646, train_F1_score: 0.76952, val_F1_score: 0.76952, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSVLHwpcgUOf",
        "outputId": "3869c649-d6c8-46f9-9853-5a813031626b"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.56557, val_loss: 0.63634, train_F1_score: 0.77070, val_F1_score: 0.77070, \n",
            "Epoch: 2 | train_loss: 0.56553, val_loss: 0.63630, train_F1_score: 0.77042, val_F1_score: 0.77042, \n",
            "Epoch: 3 | train_loss: 0.56457, val_loss: 0.63628, train_F1_score: 0.77032, val_F1_score: 0.77032, \n",
            "Epoch: 4 | train_loss: 0.56495, val_loss: 0.63628, train_F1_score: 0.77088, val_F1_score: 0.77088, \n",
            "Epoch: 5 | train_loss: 0.56546, val_loss: 0.63626, train_F1_score: 0.77054, val_F1_score: 0.77054, \n",
            "Epoch: 6 | train_loss: 0.56452, val_loss: 0.63627, train_F1_score: 0.77037, val_F1_score: 0.77037, \n",
            "Epoch: 7 | train_loss: 0.56398, val_loss: 0.63626, train_F1_score: 0.77150, val_F1_score: 0.77150, \n",
            "Epoch: 8 | train_loss: 0.56570, val_loss: 0.63625, train_F1_score: 0.77118, val_F1_score: 0.77118, \n",
            "Epoch: 9 | train_loss: 0.56528, val_loss: 0.63624, train_F1_score: 0.76986, val_F1_score: 0.76986, \n",
            "Epoch: 10 | train_loss: 0.56459, val_loss: 0.63624, train_F1_score: 0.77050, val_F1_score: 0.77050, \n",
            "Epoch: 11 | train_loss: 0.56557, val_loss: 0.63624, train_F1_score: 0.76971, val_F1_score: 0.76971, \n",
            "Epoch: 12 | train_loss: 0.56520, val_loss: 0.63624, train_F1_score: 0.77033, val_F1_score: 0.77033, \n",
            "Epoch: 13 | train_loss: 0.56474, val_loss: 0.63624, train_F1_score: 0.77141, val_F1_score: 0.77141, \n",
            "Epoch: 14 | train_loss: 0.56523, val_loss: 0.63624, train_F1_score: 0.77034, val_F1_score: 0.77034, \n",
            "Epoch: 15 | train_loss: 0.56564, val_loss: 0.63624, train_F1_score: 0.77023, val_F1_score: 0.77023, \n",
            "Epoch: 16 | train_loss: 0.56484, val_loss: 0.63624, train_F1_score: 0.77074, val_F1_score: 0.77074, \n",
            "Epoch: 17 | train_loss: 0.56487, val_loss: 0.63623, train_F1_score: 0.77112, val_F1_score: 0.77112, \n",
            "Epoch: 18 | train_loss: 0.56534, val_loss: 0.63623, train_F1_score: 0.77071, val_F1_score: 0.77071, \n",
            "Epoch: 19 | train_loss: 0.56583, val_loss: 0.63623, train_F1_score: 0.76985, val_F1_score: 0.76985, \n",
            "Epoch: 20 | train_loss: 0.56510, val_loss: 0.63623, train_F1_score: 0.77000, val_F1_score: 0.77000, \n",
            "Epoch: 21 | train_loss: 0.56504, val_loss: 0.63623, train_F1_score: 0.77079, val_F1_score: 0.77079, \n",
            "Epoch: 22 | train_loss: 0.56518, val_loss: 0.63623, train_F1_score: 0.77048, val_F1_score: 0.77048, \n",
            "Epoch: 23 | train_loss: 0.56520, val_loss: 0.63623, train_F1_score: 0.77092, val_F1_score: 0.77092, \n",
            "Epoch: 24 | train_loss: 0.56505, val_loss: 0.63623, train_F1_score: 0.77006, val_F1_score: 0.77006, \n",
            "Epoch: 25 | train_loss: 0.56523, val_loss: 0.63622, train_F1_score: 0.77052, val_F1_score: 0.77052, \n",
            "Epoch: 26 | train_loss: 0.56499, val_loss: 0.63622, train_F1_score: 0.77004, val_F1_score: 0.77004, \n",
            "Epoch: 27 | train_loss: 0.56613, val_loss: 0.63622, train_F1_score: 0.76941, val_F1_score: 0.76941, \n",
            "Epoch: 28 | train_loss: 0.56415, val_loss: 0.63622, train_F1_score: 0.77084, val_F1_score: 0.77084, \n",
            "Epoch: 29 | train_loss: 0.56459, val_loss: 0.63622, train_F1_score: 0.77079, val_F1_score: 0.77079, \n",
            "Epoch: 30 | train_loss: 0.56502, val_loss: 0.63622, train_F1_score: 0.77180, val_F1_score: 0.77180, \n",
            "Epoch: 31 | train_loss: 0.56613, val_loss: 0.63621, train_F1_score: 0.77016, val_F1_score: 0.77016, \n",
            "Epoch: 32 | train_loss: 0.56533, val_loss: 0.63621, train_F1_score: 0.77014, val_F1_score: 0.77014, \n",
            "Epoch: 33 | train_loss: 0.56496, val_loss: 0.63621, train_F1_score: 0.77081, val_F1_score: 0.77081, \n",
            "Epoch: 34 | train_loss: 0.56446, val_loss: 0.63621, train_F1_score: 0.77084, val_F1_score: 0.77084, \n",
            "Epoch: 35 | train_loss: 0.56538, val_loss: 0.63621, train_F1_score: 0.76994, val_F1_score: 0.76994, \n",
            "Epoch: 36 | train_loss: 0.56557, val_loss: 0.63621, train_F1_score: 0.77031, val_F1_score: 0.77031, \n",
            "Epoch: 37 | train_loss: 0.56484, val_loss: 0.63621, train_F1_score: 0.77067, val_F1_score: 0.77067, \n",
            "Epoch: 38 | train_loss: 0.56515, val_loss: 0.63621, train_F1_score: 0.76975, val_F1_score: 0.76975, \n",
            "Epoch: 39 | train_loss: 0.56368, val_loss: 0.63621, train_F1_score: 0.77112, val_F1_score: 0.77112, \n",
            "Epoch: 40 | train_loss: 0.56652, val_loss: 0.63621, train_F1_score: 0.77009, val_F1_score: 0.77009, \n",
            "Epoch: 41 | train_loss: 0.56528, val_loss: 0.63621, train_F1_score: 0.76989, val_F1_score: 0.76989, \n",
            "Epoch: 42 | train_loss: 0.56435, val_loss: 0.63621, train_F1_score: 0.77165, val_F1_score: 0.77165, \n",
            "Epoch: 43 | train_loss: 0.56452, val_loss: 0.63621, train_F1_score: 0.77218, val_F1_score: 0.77218, \n",
            "Epoch: 44 | train_loss: 0.56512, val_loss: 0.63621, train_F1_score: 0.77127, val_F1_score: 0.77127, \n",
            "Epoch: 45 | train_loss: 0.56533, val_loss: 0.63621, train_F1_score: 0.76987, val_F1_score: 0.76987, \n",
            "Epoch: 46 | train_loss: 0.56575, val_loss: 0.63621, train_F1_score: 0.77103, val_F1_score: 0.77103, \n",
            "Epoch: 47 | train_loss: 0.56654, val_loss: 0.63621, train_F1_score: 0.77099, val_F1_score: 0.77099, \n",
            "Epoch: 48 | train_loss: 0.56518, val_loss: 0.63621, train_F1_score: 0.77191, val_F1_score: 0.77191, \n",
            "Epoch: 49 | train_loss: 0.56562, val_loss: 0.63621, train_F1_score: 0.77076, val_F1_score: 0.77076, \n",
            "Epoch: 50 | train_loss: 0.56607, val_loss: 0.63621, train_F1_score: 0.77068, val_F1_score: 0.77068, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "Pv6uw9Rmgx-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "blLCx0YcEnRu"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance"
      ],
      "metadata": {
        "id": "202BEMlBhCiC"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "metadata": {
        "id": "QuF9LlBrhPqr"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_true, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MimL4MLvhbTf",
        "outputId": "6ed1df8c-8c34-4de8-e6a9-a3709a3a2692"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.7728983536971095,\n",
            "  \"recall\": 0.75235,\n",
            "  \"f1\": 0.7534082475175906,\n",
            "  \"num_samples\": 60000.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "kskjHQOgk_pe"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save artifacts\n",
        "dir = Path('artifacts')\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "label_encoder.save(fp=Path(dir, 'label_encoder.json'))\n",
        "tokenizer.save(fp=Path(dir, 'tokenizer.json'))\n",
        "torch.save(best_model.state_dict(), Path(dir, 'model.pt'))\n",
        "with open(Path(dir, 'performance.json'), 'w') as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)\n"
      ],
      "metadata": {
        "id": "ryERHDr1kt1A"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "kKDnh6-WnUT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probability_distribution(y_prob, classes):\n",
        "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
        "    results = {}\n",
        "    for i, class_ in enumerate(classes):\n",
        "        results[class_] = np.float64(y_prob[i])\n",
        "    sorted_results = {k: v for k, v in sorted(\n",
        "        results.items(), key=lambda item: item[1], reverse=True)}\n",
        "    return sorted_results\n"
      ],
      "metadata": {
        "id": "-Yvrls45nTXY"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load artifacts\n",
        "device = torch.device('cpu')\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenizer.json'))\n",
        "model = RNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    hidden_size=HIDDEN_DIM,\n",
        "    dropout_prob=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9xx-aa6nHqQ",
        "outputId": "84891090-22f6-4f6a-c52f-108d4cc357fe"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(5000, 100, padding_idx=0)\n",
              "  (rnn): RNN(100, 128, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "metadata": {
        "id": "l1IdMnVZo0ib"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "text = 'The final tennis tournament starts next week.'\n",
        "X = tokenizer.texts_to_sequences([preprocess(text)])\n",
        "print (tokenizer.sequences_to_texts(X))\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
        "dataset = Dataset(X=X, y=y_filler)\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Lx3DaJp02h",
        "outputId": "ba029a63-f908-44ad-9e52-7784a87af8c2"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['final', '<UNK>', '<UNK>', '<UNK>', 'next', 'week']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict(dataloader)\n",
        "y_pred = np.argmax(y_prob,axis = 1)\n",
        "print(y_pred)\n",
        "label_encoder.decode(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHiBJcrop_hc",
        "outputId": "515c1767-775d-4559-ef48-75b309226d45"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Sports'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distributions\n",
        "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
        "print (json.dumps(prob_dist, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50zvBq0jqCA_",
        "outputId": "b15c6de8-9d65-4d24-a812-fb9005db5b04"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sports\": 0.45584022998809814,\n",
            "  \"World\": 0.3801567852497101,\n",
            "  \"Sci/Tech\": 0.14259421825408936,\n",
            "  \"Business\": 0.021408775821328163\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QxDGHR38iqGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3mnq6TBkr-rL"
      },
      "execution_count": 53,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}